# Production‑Grade DevSecOps Terraform Starter (AWS)

A complete, opinionated Terraform scaffold for AWS that’s ready for DevSecOps:

* **Modular IaC** (VPC, Security Groups, EC2, IAM instance profile)
* **Remote state** (S3 + DynamoDB locking)
* **Per‑env configuration** (`envs/dev|test|prod`)
* **Security gates**: Terrascan, Checkov, TFLint
* **Policy‑as‑code**: OPA/Conftest examples
* **CI/CD**: GitHub Actions pipeline with plan artifact & approvals
* **Pre‑commit** hooks: fmt/validate/lint/scan

> Works with Terraform ≥ 1.5 and AWS provider ≥ 5.x.

---

## Repository Layout

```text
terraform-aws-devsecops/
├─ README.md
├─ .gitignore
├─ .pre-commit-config.yaml
├─ .tflint.hcl
├─ .checkov.yaml
├─ terrascan-config.toml
├─ policies/
│  └─ conftest/
│     └─ terraform/
│        ├─ deny_open_cidr.rego
│        └─ require_tags.rego
├─ .github/
│  └─ workflows/
│     └─ terraform-ci.yml
├─ versions.tf
├─ providers.tf
├─ variables.tf
├─ outputs.tf
├─ main.tf
├─ modules/
│  ├─ vpc/
│  │  ├─ main.tf
│  │  ├─ variables.tf
│  │  └─ outputs.tf
│  ├─ security_group/
│  │  ├─ main.tf
│  │  └─ variables.tf
│  └─ ec2/
│     ├─ main.tf
│     ├─ variables.tf
│     └─ outputs.tf
└─ envs/
   ├─ dev/
   │  ├─ terraform.tfvars
   │  └─ backend.hcl
   ├─ test/
   │  ├─ terraform.tfvars
   │  └─ backend.hcl
   └─ prod/
      ├─ terraform.tfvars
      └─ backend.hcl
```

---

## Root: versions.tf

```hcl
terraform {
  required_version = ">= 1.5.0"

  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 5.0"
    }
  }
}
```

## Root: providers.tf

```hcl
provider "aws" {
  region = var.region
}
```

## Root: variables.tf

```hcl
variable "project" {
  description = "Project name for tagging"
  type        = string
  default     = "nandeesh-devsecops"
}

variable "environment" {
  description = "Environment identifier (dev/test/prod)"
  type        = string
}

variable "region" {
  description = "AWS region"
  type        = string
}

variable "vpc_cidr" {
  description = "VPC CIDR block"
  type        = string
  default     = "10.0.0.0/16"
}

variable "public_subnet_cidrs" {
  description = "List of public subnet CIDRs"
  type        = list(string)
  default     = ["10.0.1.0/24", "10.0.2.0/24"]
}

variable "private_subnet_cidrs" {
  description = "List of private subnet CIDRs"
  type        = list(string)
  default     = ["10.0.101.0/24", "10.0.102.0/24"]
}

variable "create_nat_gateway" {
  description = "Create a NAT Gateway for private subnets"
  type        = bool
  default     = true
}

variable "allowed_ssh_cidrs" {
  description = "CIDR ranges allowed to SSH"
  type        = list(string)
  default     = []
}

variable "instance_type" {
  description = "EC2 instance type"
  type        = string
  default     = "t3.micro"
}

variable "instance_count" {
  description = "Number of EC2 instances"
  type        = number
  default     = 1
}

variable "key_name" {
  description = "Existing EC2 key pair for SSH"
  type        = string
}

variable "extra_tags" {
  description = "Additional resource tags"
  type        = map(string)
  default     = {}
}
```

## Root: outputs.tf

```hcl
output "vpc_id" {
  value = module.vpc.vpc_id
}

output "public_subnet_ids" {
  value = module.vpc.public_subnet_ids
}

output "instance_ids" {
  value = module.ec2.instance_ids
}
```

## Root: main.tf

```hcl
locals {
  common_tags = merge({
    Project     = var.project,
    Environment = var.environment,
    ManagedBy   = "terraform"
  }, var.extra_tags)
}

module "vpc" {
  source               = "./modules/vpc"
  vpc_cidr             = var.vpc_cidr
  public_subnet_cidrs  = var.public_subnet_cidrs
  private_subnet_cidrs = var.private_subnet_cidrs
  create_nat_gateway   = var.create_nat_gateway
  tags                 = local.common_tags
}

module "sg_app" {
  source           = "./modules/security_group"
  name             = "app-sg-${var.environment}"
  vpc_id           = module.vpc.vpc_id
  allowed_ssh_cidrs= var.allowed_ssh_cidrs
  tags             = local.common_tags
}

module "ec2" {
  source              = "./modules/ec2"
  instance_count      = var.instance_count
  instance_type       = var.instance_type
  subnet_ids          = module.vpc.public_subnet_ids
  security_group_ids  = [module.sg_app.id]
  key_name            = var.key_name
  iam_instance_profile= null
  tags                = local.common_tags
}
```

---

## Module: VPC (`modules/vpc`)

### modules/vpc/variables.tf

```hcl
variable "vpc_cidr" { type = string }
variable "public_subnet_cidrs" { type = list(string) }
variable "private_subnet_cidrs" { type = list(string) }
variable "create_nat_gateway" { type = bool }
variable "tags" { type = map(string) }
```

### modules/vpc/main.tf

```hcl
resource "aws_vpc" "this" {
  cidr_block           = var.vpc_cidr
  enable_dns_support   = true
  enable_dns_hostnames = true
  tags = merge(var.tags, { Name = "vpc" })
}

resource "aws_internet_gateway" "this" {
  vpc_id = aws_vpc.this.id
  tags   = merge(var.tags, { Name = "igw" })
}

# Public subnets + route tables
resource "aws_subnet" "public" {
  for_each                = { for idx, cidr in var.public_subnet_cidrs : idx => cidr }
  vpc_id                  = aws_vpc.this.id
  cidr_block              = each.value
  map_public_ip_on_launch = true
  tags = merge(var.tags, { Name = "public-${each.key}" , Tier = "public" })
}

resource "aws_route_table" "public" {
  vpc_id = aws_vpc.this.id
  tags   = merge(var.tags, { Name = "rtb-public" })
}

resource "aws_route" "public_internet" {
  route_table_id         = aws_route_table.public.id
  destination_cidr_block = "0.0.0.0/0"
  gateway_id             = aws_internet_gateway.this.id
}

resource "aws_route_table_association" "public_assoc" {
  for_each       = aws_subnet.public
  subnet_id      = each.value.id
  route_table_id = aws_route_table.public.id
}

# Private subnets + (optional) NAT
resource "aws_subnet" "private" {
  for_each   = { for idx, cidr in var.private_subnet_cidrs : idx => cidr }
  vpc_id     = aws_vpc.this.id
  cidr_block = each.value
  tags       = merge(var.tags, { Name = "private-${each.key}", Tier = "private" })
}

resource "aws_eip" "nat" {
  count = var.create_nat_gateway ? 1 : 0
  vpc   = true
  tags  = merge(var.tags, { Name = "eip-nat" })
}

resource "aws_nat_gateway" "this" {
  count         = var.create_nat_gateway ? 1 : 0
  allocation_id = aws_eip.nat[0].id
  subnet_id     = values(aws_subnet.public)[0].id
  tags          = merge(var.tags, { Name = "nat-gw" })
  depends_on    = [aws_internet_gateway.this]
}

resource "aws_route_table" "private" {
  vpc_id = aws_vpc.this.id
  count  = length(var.private_subnet_cidrs) > 0 ? 1 : 0
  tags   = merge(var.tags, { Name = "rtb-private" })
}

resource "aws_route" "private_nat" {
  count                 = var.create_nat_gateway ? 1 : 0
  route_table_id         = aws_route_table.private[0].id
  destination_cidr_block = "0.0.0.0/0"
  nat_gateway_id         = aws_nat_gateway.this[0].id
}

resource "aws_route_table_association" "private_assoc" {
  for_each = aws_subnet.private
  subnet_id      = each.value.id
  route_table_id = aws_route_table.private[0].id
}
```

### modules/vpc/outputs.tf

```hcl
output "vpc_id" { value = aws_vpc.this.id }
output "public_subnet_ids" { value = [for s in aws_subnet.public : s.id] }
output "private_subnet_ids" { value = [for s in aws_subnet.private : s.id] }
```

---

## Module: Security Group (`modules/security_group`)

### modules/security\_group/variables.tf

```hcl
variable "name" { type = string }
variable "vpc_id" { type = string }
variable "allowed_ssh_cidrs" { type = list(string) }
variable "tags" { type = map(string) }
```

### modules/security\_group/main.tf

```hcl
resource "aws_security_group" "this" {
  name        = var.name
  description = "App SG"
  vpc_id      = var.vpc_id

  dynamic "ingress" {
    for_each = var.allowed_ssh_cidrs
    content {
      description = "SSH"
      from_port   = 22
      to_port     = 22
      protocol    = "tcp"
      cidr_blocks = [ingress.value]
    }
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
    ipv6_cidr_blocks = ["::/0"]
  }

  tags = merge(var.tags, { Name = var.name })
}

output "id" { value = aws_security_group.this.id }
```

---

## Module: EC2 (`modules/ec2`)

### modules/ec2/variables.tf

```hcl
variable "instance_count" { type = number }
variable "instance_type" { type = string }
variable "subnet_ids" { type = list(string) }
variable "security_group_ids" { type = list(string) }
variable "key_name" { type = string }
variable "iam_instance_profile" { type = string, default = null }
variable "tags" { type = map(string) }
```

### modules/ec2/main.tf

```hcl
# Use latest Amazon Linux 2 AMI via SSM Parameter for the current region
data "aws_ssm_parameter" "amzn2_ami" {
  name = "/aws/service/ami-amazon-linux-latest/al2023-ami-kernel-default-x86_64"
}

data "aws_ami" "selected" {
  most_recent = true
  owners      = ["137112412989"] # Amazon
  filter {
    name   = "image-id"
    values = [data.aws_ssm_parameter.amzn2_ami.value]
  }
}

resource "aws_instance" "this" {
  count         = var.instance_count
  ami           = data.aws_ami.selected.id
  instance_type = var.instance_type
  subnet_id     = element(var.subnet_ids, count.index % length(var.subnet_ids))
  vpc_security_group_ids = var.security_group_ids
  key_name      = var.key_name

  iam_instance_profile = var.iam_instance_profile

  metadata_options {
    http_endpoint = "enabled"
    http_tokens   = "required" # IMDSv2
  }

  root_block_device {
    encrypted = true
    volume_size = 16
    volume_type = "gp3"
  }

  tags = merge(var.tags, { Name = "ec2-${count.index}" })
}

output "instance_ids" {
  value = [for i in aws_instance.this : i.id]
}
```

---

## Environments

### envs/dev/terraform.tfvars

```hcl
environment        = "dev"
region             = "ap-south-1"
allowed_ssh_cidrs  = ["YOUR.IP.ADDR.0/24"]
instance_type      = "t3.micro"
instance_count     = 1
key_name           = "your-keypair-name"
extra_tags = {
  Owner = "Nandeesh"
}
```

### envs/test/terraform.tfvars

```hcl
environment        = "test"
region             = "ap-south-1"
allowed_ssh_cidrs  = ["YOUR.IP.ADDR.0/24"]
instance_type      = "t3.micro"
instance_count     = 2
key_name           = "your-keypair-name"
```

### envs/prod/terraform.tfvars

```hcl
environment        = "prod"
region             = "ap-south-1"
allowed_ssh_cidrs  = ["YOUR.OFFICE.IP/32"]
instance_type      = "t3.small"
instance_count     = 2
key_name           = "your-keypair-name"
extra_tags = {
  Criticality = "high"
}
```

### Remote State Backends (per env)

> Backend settings can’t use variables—provide an HCL file per env.

#### envs/dev/backend.hcl

```hcl
bucket         = "tfstate-nandeesh-dev"
key            = "terraform/state/dev.tfstate"
region         = "ap-south-1"
dynamodb_table = "tfstate-locks"
encrypt        = true
```

(Repeat for test/prod with different keys/buckets as needed.)

---

## Security & Policy Configs

### .tflint.hcl

```hcl
plugin "aws" {
  enabled = true
  version = ">= 0.36.0"
}

enable_rule = [
  "aws_instance_invalid_type",
  "terraform_deprecated_interpolation",
  "terraform_unused_declarations"
]
```

### .checkov.yaml

```yaml
quiet: false
skip-download: false
framework: terraform
soft-fail: false
skip-check: []
```

### terrascan-config.toml

```toml
[scanner]
iac_type = "terraform"
```

### OPA / Conftest policies

#### policies/conftest/terraform/deny\_open\_cidr.rego

```rego
package terraform.security

deny[msg] {
  input.resource.kind == "aws_security_group"
  ingress := input.resource.config.ingress[_]
  contains(ingress.cidr_blocks, "0.0.0.0/0")
  msg := sprintf("Open ingress to 0.0.0.0/0 not allowed: %v", [input.resource.name])
}
```

#### policies/conftest/terraform/require\_tags.rego

```rego
package terraform.tags

required := {"Project", "Environment", "ManagedBy"}

deny[msg] {
  tags := input.resource.values.tags
  some k
  k := required[_]
  not tags[k]
  msg := sprintf("Missing required tag %v on %v", [k, input.resource.name])
}
```

> Use `terraform show -json plan.out | conftest test -p policies -` to evaluate plan JSON against OPA. (In CI we do this automatically.)

---

## Pre‑commit Hooks

### .pre-commit-config.yaml

```yaml
repos:
  - repo: https://github.com/antonbabenko/pre-commit-terraform
    rev: v1.90.0
    hooks:
      - id: terraform_fmt
      - id: terraform_validate
      - id: terraform_tflint
      - id: terraform_checkov
      - id: terraform_terrascan
```

Run once:

```bash
pip install pre-commit
pre-commit install
```

---

## CI/CD (GitHub Actions)

### .github/workflows/terraform-ci.yml

```yaml
name: terraform-ci

on:
  pull_request:
    branches: [ main ]
  push:
    branches: [ main ]

jobs:
  plan:
    runs-on: ubuntu-latest
    env:
      TF_IN_AUTOMATION: "true"
    steps:
      - uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.7.5

      - name: Install tools
        run: |
          curl -sSL https://raw.githubusercontent.com/terraform-linters/tflint/master/install_linux.sh | bash
          pip install checkov
          curl -L https://github.com/tenable/terrascan/releases/latest/download/terrascan_Linux_x86_64.tar.gz | tar -xz && sudo mv terrascan /usr/local/bin/
          curl -L https://github.com/open-policy-agent/conftest/releases/latest/download/conftest_Linux_x86_64.tar.gz | tar -xz && sudo mv conftest /usr/local/bin/

      - name: Select env
        run: |
          echo "ENVIRONMENT=${{ github.event.pull_request.base.ref == 'main' && 'dev' || 'dev' }}" >> $GITHUB_ENV

      - name: Backend init
        run: |
          terraform init -backend-config=envs/dev/backend.hcl

      - name: Validate & Lint
        run: |
          terraform validate
          tflint --no-color

      - name: Security Scans
        run: |
          checkov -d .
          terrascan scan -i terraform -d .

      - name: Plan (dev)
        run: |
          terraform plan \
            -var-file=envs/dev/terraform.tfvars \
            -out=plan.out

      - name: Export plan JSON for OPA
        run: terraform show -json plan.out > plan.json

      - name: OPA Policy Check
        run: conftest test -p policies plan.json

      - name: Upload plan artifact
        uses: actions/upload-artifact@v4
        with:
          name: tf-plan
          path: plan.out

  apply:
    if: github.ref == 'refs/heads/main'
    needs: [plan]
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write
    steps:
      - uses: actions/checkout@v4
      - uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.7.5
      - name: Download plan
        uses: actions/download-artifact@v4
        with:
          name: tf-plan
          path: .
      - name: Init backend
        run: terraform init -backend-config=envs/dev/backend.hcl
      - name: Apply (requires manual job approval in protected env)
        run: terraform apply -auto-approve plan.out
```

> Protect the `apply` job with GitHub Environments and required reviewers for production.

---

## .gitignore

```gitignore
.terraform/
*.tfstate
*.tfstate.*
crash.log
*.plan
plan.out
plan.json
.terraform.lock.hcl
```

---

## S3/DynamoDB for Remote State (one‑time setup)

Create an S3 bucket and DynamoDB table **before** `terraform init` (can be done manually or via a bootstrap script):

```bash
aws s3api create-bucket \
  --bucket tfstate-nandeesh-dev \
  --region ap-south-1 \
  --create-bucket-configuration LocationConstraint=ap-south-1

aws dynamodb create-table \
  --table-name tfstate-locks \
  --attribute-definitions AttributeName=LockID,AttributeType=S \
  --key-schema AttributeName=LockID,KeyType=HASH \
  --billing-mode PAY_PER_REQUEST
```

(Repeat/bucket-per-env as your org requires.)

---

## Usage

```bash
# From repo root
terraform init -backend-config=envs/dev/backend.hcl
terraform plan -var-file=envs/dev/terraform.tfvars -out=plan.out
terraform apply plan.out

# Destroy safely
terraform plan -destroy -var-file=envs/dev/terraform.tfvars -out=destroy.out
terraform apply destroy.out
```

---

## Hardening Notes (Why This Is Production‑Ready)

* **Pinned provider & TF versions** to avoid supply‑chain drift.
* **Remote state with locking** to prevent concurrent corruption.
* **IMDSv2 required**, **EBS encryption enabled** by default.
* **NAT Gateway optional** to save cost in non‑prod.
* **No open SSH by default** – you must declare `allowed_ssh_cidrs`.
* **Policy‑as‑code gates** (OPA) to block 0.0.0.0/0 and enforce tags.
* **Multi‑scanner** approach (TFLint + Checkov + Terrascan) for coverage.
* **Reviewed plan artifact**: plan/apply split in CI.
* **Pre‑commit hooks** to catch issues locally before pushing.

---

## Next Steps You Can Take

* Add modules for **RDS**, **ALB/Target Groups**, **Autoscaling Groups**, **ECR/ECS/EKS** as needed.
* Configure **AWS SSO/OIDC** in CI and remove long‑lived creds.
* Add **CloudTrail/Config/GuardDuty** baselines via modules.
* Extend OPA policies to your org standards (mandatory KMS keys, tag schema, region allow‑list, etc.).

---

**Tip:** Replace `YOUR.IP.ADDR.0/24` and `your-keypair-name` in `envs/*/terraform.tfvars` before running.
